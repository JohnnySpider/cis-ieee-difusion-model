{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a2df2ad3-df8f-403d-b558-c961a3169220",
   "metadata": {},
   "source": [
    "# Primeiro rascunho das funções do modelo de difusão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cb1ebd8f-6a26-4fe6-8f52-8b7cf4b11dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
    "tf.config.set_visible_devices([], 'GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "33c33209-2eca-4d81-a690-3e4939a94dd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.18.0\n",
      "tf.Tensor([1 2 3 4 5], shape=(5,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# testar tensforflow:\n",
    "print(tf.__version__)\n",
    "tensor = tf.constant([1, 2, 3, 4, 5])\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f7a2df0-66aa-45f2-a4df-2db77b870b1f",
   "metadata": {},
   "source": [
    "## 1. Carregar dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4fcd33e7-993f-4fca-a3a8-04e20f2efe08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir constantes (rascunho)\n",
    "IMG_SIZE = 256  \n",
    "BATCH_SIZE = 32  \n",
    "TRAIN_SPLIT = 0.8  \n",
    "VAL_SPLIT = 0.2  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b170bb6f-7ac3-47a9-b46a-51d9a29f3a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_preprocess_image(image, label):\n",
    "    image = tf.image.resize(image, [IMG_SIZE, IMG_SIZE])\n",
    "    \n",
    "    image = tf.cast(image, tf.float32) / 255.0\n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "540e017c-5757-4c3b-9bdb-3ec8ded07b33",
   "metadata": {},
   "source": [
    "### load_and_preprocess_image: Redimensiona e normaliza uma imagem. Retorna a imagem normalizada e o label/rotulo\n",
    "    \n",
    "- Parâmetros:\n",
    "    - image: A imagem a ser processada.\n",
    "    - label: O label associado à imagem.\n",
    "\n",
    "- (Resize): função tf.cast(image, tf.float32): Converte os valores de pixel da imagem para float. Geralmente, imagens carregadas de arquivos têm valores de pixel inteiros entre 0 e 255. Para redes neurais, aparentemente trabalhar com float32 é a maneira mais comum.\n",
    "\n",
    "- (Normalize): Divisão por 255.0 (normalização): Após a conversão, cada valor de pixel é dividido por 255.0 para ajustar o intervalo dos valores de pixel de [0, 255] para [0, 1]. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3926952f-1a70-4494-a132-716b5af7f3f3",
   "metadata": {},
   "source": [
    "## 2 Divisão em Conjuntos de Treinamento, Validação e Teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e1c4036b-6a35-4d48-a0d6-30d019bfec10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(dataset, train_split=TRAIN_SPLIT, val_split=VAL_SPLIT):\n",
    "    # Calcular o número total de exemplos\n",
    "    total_examples = dataset.cardinality().numpy()\n",
    "    \n",
    "    # Calcular o número de exemplos para cada conjunto\n",
    "    train_size = int(total_examples * train_split)\n",
    "    val_size = int(total_examples * val_split)\n",
    "    \n",
    "    # Dividir o dataset\n",
    "    train_ds = dataset.take(train_size)\n",
    "    remaining_ds = dataset.skip(train_size)\n",
    "    val_ds = remaining_ds.take(val_size)\n",
    "    \n",
    "    return train_ds, val_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02f494ff-7279-492b-a4a9-b74dab7113de",
   "metadata": {},
   "source": [
    "### load_and_preprocess_image: Divide o conjunto de dados em treinamento, validação e teste. Retorna os conjuntos de treino e validação\n",
    "\n",
    "- Parâmetros:\n",
    "    - dataset: O conjunto de dados completo.\n",
    "    - train_split: Proporção de dados para treinamento.\n",
    "    - val_split: Proporção de dados para validação.\n",
    "\n",
    "total_examples: A primeira coisa que a função faz é calcular o número total de exemplos presentes no dataset usando a propriedade .cardinality(), que retorna o número de elementos no tf.data.Dataset. Esse valor é convertido para numpy() para ser manipulado como um número inteiro."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cda6c29-4686-499a-b932-b22a5f7265ce",
   "metadata": {},
   "source": [
    "## 3. Carregar e Pré-processar a Base de Dados, Dividir Conjuntos e Preparar Pipeline para Treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "35153e92-16bf-4985-be5a-5384a5a13e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataset(batch_size=BATCH_SIZE):\n",
    "    # Carregar o dataset CIFAR-10 (apenas dados de treino)\n",
    "    dataset, info = tfds.load('cifar10', split='train', as_supervised=True, with_info=True)\n",
    "    \n",
    "    # Aplicar pré-processamento em cada exemplo do dataset\n",
    "    dataset = dataset.map(load_and_preprocess_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    \n",
    "    # Dividir o dataset\n",
    "    train_ds, val_ds = split_dataset(dataset)\n",
    "    \n",
    "    # Configurar o conjunto de treinamento e validação com embaralhamento, batch e prefetching -  estudar casos de uso e importância\n",
    "    train_ds = train_ds.shuffle(1000).batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "    val_ds = val_ds.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "    \n",
    "    return train_ds, val_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "134c00ea-ba67-4537-9dbd-392f446dabb8",
   "metadata": {},
   "source": [
    "### prepare_dataset: Prepara o dataset para o treinamento, incluindo carregamento, pré-processamento e divisão. Retorna o dataset de treino e o de validação\n",
    "    \n",
    "- Parâmetros:\n",
    "    - batch_size: Tamanho do batch.\n",
    "\n",
    "- shuffle: O embaralhamento dos dados é uma técnica para garantir que o modelo não aprenda padrões artificiais devido à ordem dos dados. Se os dados forem processados na ordem em que foram carregados, pode haver correlação entre exemplos consecutivos (como, por exemplo, uma sequência de imagens de uma única classe). Isso pode levar a overfitting ou a um treinamento menos eficaz.\n",
    "\n",
    "- batching: O batching divide o dataset em pequenos batches ou lotes de dados. Cada lote contém um número fixo de exemplos, que são processados juntos durante a fase de treinamento. O batching é essencial para permitir que o modelo seja treinado em grandes volumes de dados sem sobrecarregar a memória."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
